{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe930e70550a40fa8e8a055a8bcb1859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c750a835127243a5b15f1b798fb082b7",
              "IPY_MODEL_d2dfa28ce8994379b976410df53cd28d",
              "IPY_MODEL_fcf34890e24f42af8835215058fbbbe0"
            ],
            "layout": "IPY_MODEL_285ff74a2d69467bb3f8b549f31c122e"
          }
        },
        "c750a835127243a5b15f1b798fb082b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9e7a7bc82b743c9a33310acad5b0d83",
            "placeholder": "​",
            "style": "IPY_MODEL_b6be201049df450bbcca7926198e74bc",
            "value": "  0%"
          }
        },
        "d2dfa28ce8994379b976410df53cd28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69d9c9d345f04831af50367ec90757a9",
            "max": 162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a63e5553af774f6ab2f3a5509f5979b9",
            "value": 0
          }
        },
        "fcf34890e24f42af8835215058fbbbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9af8d683a024bfabf5ad20f83bb1dba",
            "placeholder": "​",
            "style": "IPY_MODEL_aed5aa0d862c446e9ce7ed41a4b26803",
            "value": " 0/162 [00:00&lt;?, ?it/s]"
          }
        },
        "285ff74a2d69467bb3f8b549f31c122e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e7a7bc82b743c9a33310acad5b0d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6be201049df450bbcca7926198e74bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69d9c9d345f04831af50367ec90757a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63e5553af774f6ab2f3a5509f5979b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9af8d683a024bfabf5ad20f83bb1dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed5aa0d862c446e9ce7ed41a4b26803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.fft import fft, ifft, fftfreq\n",
        "from scipy.signal import firwin, freqz, lfilter, welch\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install mne\n",
        "!pip install moabb\n",
        "!pip install braindecode\n",
        "\n",
        "import mne\n",
        "import moabb\n",
        "from mne.decoding import CSP\n",
        "from moabb.datasets import BNCI2014_001\n",
        "from moabb.evaluations import WithinSessionEvaluation\n",
        "from moabb.paradigms import LeftRightImagery"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fUZj-JZ6SDT",
        "outputId": "16a2b47b-4965-4a1d-f2ef-515122b81aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: braindecode in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from braindecode) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from braindecode) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from braindecode) (3.13.0)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from braindecode) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from braindecode) (0.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.5.0)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (from braindecode) (1.8.0)\n",
            "Requirement already satisfied: docstring-inheritance in /usr/local/lib/python3.11/dist-packages (from braindecode) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode) (2.9.0.post0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->braindecode) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode) (1.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne->braindecode) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode) (2025.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode) (1.5.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->braindecode) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->braindecode) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->braindecode) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->braindecode) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->braindecode) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->braindecode) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2025.4.26)\n",
            "Requirement already satisfied: moabb in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (6.0.2)\n",
            "Requirement already satisfied: coverage<8.0.0,>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (7.8.2)\n",
            "Requirement already satisfied: edfio<0.5.0,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (0.4.9)\n",
            "Requirement already satisfied: edflib-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.0.8)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (3.13.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (3.10.0)\n",
            "Requirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (0.61.0)\n",
            "Requirement already satisfied: mne<2.0.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.9.0)\n",
            "Requirement already satisfied: mne-bids>=0.14 in /usr/local/lib/python3.11/dist-packages (from moabb) (0.16.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.22 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from moabb) (2.2.2)\n",
            "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.8.2)\n",
            "Requirement already satisfied: pyriemann<0.8,>=0.7 in /usr/local/lib/python3.11/dist-packages (from moabb) (0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn<1.6 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.5.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.15.3)\n",
            "Requirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (0.12.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from moabb) (4.67.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.15 in /usr/local/lib/python3.11/dist-packages (from moabb) (1.26.20)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.9.0.post0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb) (5.9.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne<2.0.0,>=1.7.0->moabb) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->moabb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.2->moabb) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch<2.0.0,>=1.6.0->moabb) (4.3.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pyriemann<0.8,>=0.7->moabb) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6->moabb) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne<2.0.0,>=1.7.0->moabb) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from braindecode.datasets import MOABBDataset"
      ],
      "metadata": {
        "id": "GyBU01jF_2Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids = [i for i in range(1, 10)])"
      ],
      "metadata": {
        "id": "WY6p-BwN-9xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from braindecode.preprocessing import create_windows_from_events\n",
        "\n",
        "trial_start_offset_seconds = -0.5\n",
        "# Extract sampling frequency, check that they are same in all datasets\n",
        "sfreq = dataset.datasets[0].raw.info[\"sfreq\"]\n",
        "assert all([ds.raw.info[\"sfreq\"] == sfreq for ds in dataset.datasets])\n",
        "# Calculate the trial start offset in samples.\n",
        "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
        "\n",
        "# Create windows using braindecode function for this. It needs parameters to define how\n",
        "# trials should be used.\n",
        "windows_dataset = create_windows_from_events(\n",
        "    dataset,\n",
        "    trial_start_offset_samples=trial_start_offset_samples,\n",
        "    trial_stop_offset_samples=0,\n",
        "    preload=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CFjOQGxCt6S",
        "outputId": "cae2a595-0359-45c9-e91d-dfb4ae67e022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
            "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitted = windows_dataset.split(\"session\")\n",
        "train_set = splitted['0train']  # Session train\n",
        "test_set = splitted['1test']  # Session evaluation"
      ],
      "metadata": {
        "id": "jHSeDffDBWqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "MVCnZ24dJew6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "VHozUgyDBlxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "for batch_idx, (X, y, _) in progress_bar:\n",
        "  print(X.shape, y.shape)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "fe930e70550a40fa8e8a055a8bcb1859",
            "c750a835127243a5b15f1b798fb082b7",
            "d2dfa28ce8994379b976410df53cd28d",
            "fcf34890e24f42af8835215058fbbbe0",
            "285ff74a2d69467bb3f8b549f31c122e",
            "e9e7a7bc82b743c9a33310acad5b0d83",
            "b6be201049df450bbcca7926198e74bc",
            "69d9c9d345f04831af50367ec90757a9",
            "a63e5553af774f6ab2f3a5509f5979b9",
            "e9af8d683a024bfabf5ad20f83bb1dba",
            "aed5aa0d862c446e9ce7ed41a4b26803"
          ]
        },
        "id": "wsxo23s5B42k",
        "outputId": "5a565232-2ab4-4996-d843-8df8a7295a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/162 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe930e70550a40fa8e8a055a8bcb1859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 26, 1125]) torch.Size([16])\n",
            "tensor([0, 1, 1, 2, 1, 0, 2, 0, 1, 1, 3, 1, 3, 2, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGNetLSTM(nn.Module):\n",
        "    def __init__(self, n_classes=4, in_channels=26,\n",
        "                 F1=8, D=2, F2=16, kernel_length=64,\n",
        "                 dropout=0.25, lstm_units=64):\n",
        "        super(EEGNetLSTM, self).__init__()\n",
        "\n",
        "        # Block 1: Spatial-temporal features\n",
        "        self.conv1 = nn.Conv2d(1, F1, (1, kernel_length),\n",
        "                              padding=(0, kernel_length//2),\n",
        "                              bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(F1)\n",
        "        self.depthwise = nn.Conv2d(F1, F1*D, (in_channels, 1),\n",
        "                                  groups=F1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(F1*D)\n",
        "        self.elu1 = nn.ELU()\n",
        "        self.pool1 = nn.AvgPool2d((1, 4))\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Block 2: Temporal compression\n",
        "        self.sep_conv = nn.Conv2d(F1*D, F1*D, (1, 16),\n",
        "                                 padding=(0, 8),\n",
        "                                 groups=F1*D, bias=False)\n",
        "        self.pointwise = nn.Conv2d(F1*D, F2, (1, 1), bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(F2)\n",
        "        self.elu2 = nn.ELU()\n",
        "        self.pool2 = nn.AvgPool2d((1, 8))\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=F2,\n",
        "            hidden_size=lstm_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.classifier = nn.Linear(lstm_units, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.depthwise(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.elu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = self.sep_conv(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.elu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = x.squeeze(2)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # LSTM\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "Rs3C8cJ8OWe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EEGNetLSTM().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
        ")\n",
        "\n",
        "def train(model, train_loader, test_loader, epochs=100):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0, 0, 0\n",
        "        for X, y, _ in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).sum().item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y, _ in test_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += y.size(0)\n",
        "                val_correct += predicted.eq(y).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train: Loss {avg_train_loss:.4f} Acc {train_acc:.2f}% | \"\n",
        "              f\"Val: Loss {avg_val_loss:.4f} Acc {val_acc:.2f}% | \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "train(model, train_loader, test_loader, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZJc1yuwPiEa",
        "outputId": "fa3a9ef4-3901-47cc-ad5a-e1a52419fedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Train: Loss 1.3886 Acc 23.84% | Val: Loss 1.3865 Acc 25.00% | LR: 0.001000\n",
            "Epoch 2/100 | Train: Loss 1.3854 Acc 27.20% | Val: Loss 1.3866 Acc 25.00% | LR: 0.001000\n",
            "Epoch 3/100 | Train: Loss 1.3822 Acc 28.05% | Val: Loss 1.3867 Acc 25.00% | LR: 0.001000\n",
            "Epoch 4/100 | Train: Loss 1.3779 Acc 29.67% | Val: Loss 1.3866 Acc 25.12% | LR: 0.001000\n",
            "Epoch 5/100 | Train: Loss 1.3681 Acc 32.25% | Val: Loss 1.4018 Acc 27.12% | LR: 0.001000\n",
            "Epoch 6/100 | Train: Loss 1.3474 Acc 33.45% | Val: Loss 1.4168 Acc 27.51% | LR: 0.001000\n",
            "Epoch 7/100 | Train: Loss 1.3020 Acc 37.85% | Val: Loss 1.3281 Acc 37.54% | LR: 0.001000\n",
            "Epoch 8/100 | Train: Loss 1.2607 Acc 41.05% | Val: Loss 1.3690 Acc 32.79% | LR: 0.001000\n",
            "Epoch 9/100 | Train: Loss 1.2375 Acc 43.29% | Val: Loss 1.2469 Acc 41.94% | LR: 0.001000\n",
            "Epoch 10/100 | Train: Loss 1.2141 Acc 46.57% | Val: Loss 1.4116 Acc 38.39% | LR: 0.001000\n",
            "Epoch 11/100 | Train: Loss 1.1780 Acc 47.92% | Val: Loss 1.2352 Acc 44.25% | LR: 0.001000\n",
            "Epoch 12/100 | Train: Loss 1.1509 Acc 50.23% | Val: Loss 1.2565 Acc 43.21% | LR: 0.001000\n",
            "Epoch 13/100 | Train: Loss 1.1421 Acc 50.66% | Val: Loss 1.2048 Acc 45.41% | LR: 0.001000\n",
            "Epoch 14/100 | Train: Loss 1.1213 Acc 53.01% | Val: Loss 1.1919 Acc 49.58% | LR: 0.001000\n",
            "Epoch 15/100 | Train: Loss 1.1062 Acc 52.82% | Val: Loss 1.1948 Acc 45.91% | LR: 0.001000\n",
            "Epoch 16/100 | Train: Loss 1.1149 Acc 52.35% | Val: Loss 1.1021 Acc 54.86% | LR: 0.001000\n",
            "Epoch 17/100 | Train: Loss 1.0896 Acc 55.32% | Val: Loss 1.2621 Acc 49.77% | LR: 0.001000\n",
            "Epoch 18/100 | Train: Loss 1.0543 Acc 57.33% | Val: Loss 1.0622 Acc 56.91% | LR: 0.001000\n",
            "Epoch 19/100 | Train: Loss 1.0126 Acc 58.83% | Val: Loss 1.1089 Acc 53.59% | LR: 0.001000\n",
            "Epoch 20/100 | Train: Loss 1.0205 Acc 58.72% | Val: Loss 1.0638 Acc 56.10% | LR: 0.001000\n",
            "Epoch 21/100 | Train: Loss 0.9987 Acc 58.45% | Val: Loss 1.0060 Acc 58.99% | LR: 0.001000\n",
            "Epoch 22/100 | Train: Loss 0.9569 Acc 60.65% | Val: Loss 0.9982 Acc 59.10% | LR: 0.001000\n",
            "Epoch 23/100 | Train: Loss 0.9614 Acc 60.53% | Val: Loss 1.0051 Acc 58.76% | LR: 0.001000\n",
            "Epoch 24/100 | Train: Loss 0.9631 Acc 59.41% | Val: Loss 1.1674 Acc 49.73% | LR: 0.001000\n",
            "Epoch 25/100 | Train: Loss 0.9487 Acc 61.00% | Val: Loss 0.9999 Acc 59.76% | LR: 0.001000\n",
            "Epoch 26/100 | Train: Loss 0.9249 Acc 62.46% | Val: Loss 1.0294 Acc 56.79% | LR: 0.001000\n",
            "Epoch 27/100 | Train: Loss 0.8898 Acc 64.04% | Val: Loss 0.9666 Acc 60.61% | LR: 0.001000\n",
            "Epoch 28/100 | Train: Loss 0.8691 Acc 64.54% | Val: Loss 0.9834 Acc 59.92% | LR: 0.001000\n",
            "Epoch 29/100 | Train: Loss 0.8596 Acc 64.97% | Val: Loss 0.9783 Acc 60.65% | LR: 0.001000\n",
            "Epoch 30/100 | Train: Loss 0.8859 Acc 63.89% | Val: Loss 0.9815 Acc 59.88% | LR: 0.001000\n",
            "Epoch 31/100 | Train: Loss 0.8543 Acc 64.66% | Val: Loss 1.0145 Acc 58.72% | LR: 0.001000\n",
            "Epoch 32/100 | Train: Loss 0.8374 Acc 65.93% | Val: Loss 0.9857 Acc 58.64% | LR: 0.001000\n",
            "Epoch 33/100 | Train: Loss 0.8176 Acc 66.71% | Val: Loss 1.1933 Acc 47.26% | LR: 0.001000\n",
            "Epoch 34/100 | Train: Loss 0.8126 Acc 67.90% | Val: Loss 0.9877 Acc 60.30% | LR: 0.001000\n",
            "Epoch 35/100 | Train: Loss 0.8234 Acc 67.13% | Val: Loss 1.2063 Acc 46.53% | LR: 0.000500\n",
            "Epoch 36/100 | Train: Loss 0.8019 Acc 67.75% | Val: Loss 0.9252 Acc 63.89% | LR: 0.000500\n",
            "Epoch 37/100 | Train: Loss 0.7734 Acc 69.41% | Val: Loss 0.9351 Acc 62.69% | LR: 0.000500\n",
            "Epoch 38/100 | Train: Loss 0.7524 Acc 69.68% | Val: Loss 0.9650 Acc 62.81% | LR: 0.000500\n",
            "Epoch 39/100 | Train: Loss 0.7687 Acc 69.56% | Val: Loss 0.9155 Acc 63.12% | LR: 0.000500\n",
            "Epoch 40/100 | Train: Loss 0.7634 Acc 68.75% | Val: Loss 0.9291 Acc 64.35% | LR: 0.000500\n",
            "Epoch 41/100 | Train: Loss 0.7244 Acc 71.06% | Val: Loss 0.9075 Acc 64.20% | LR: 0.000500\n",
            "Epoch 42/100 | Train: Loss 0.7481 Acc 70.37% | Val: Loss 0.9254 Acc 63.62% | LR: 0.000500\n",
            "Epoch 43/100 | Train: Loss 0.7394 Acc 70.45% | Val: Loss 0.9207 Acc 63.85% | LR: 0.000500\n",
            "Epoch 44/100 | Train: Loss 0.7181 Acc 71.06% | Val: Loss 0.9244 Acc 63.85% | LR: 0.000500\n",
            "Epoch 45/100 | Train: Loss 0.7330 Acc 71.57% | Val: Loss 0.9032 Acc 64.20% | LR: 0.000500\n",
            "Epoch 46/100 | Train: Loss 0.7336 Acc 70.83% | Val: Loss 0.9204 Acc 64.47% | LR: 0.000500\n",
            "Epoch 47/100 | Train: Loss 0.7322 Acc 70.45% | Val: Loss 0.9012 Acc 65.70% | LR: 0.000500\n",
            "Epoch 48/100 | Train: Loss 0.7209 Acc 71.95% | Val: Loss 0.9112 Acc 64.39% | LR: 0.000500\n",
            "Epoch 49/100 | Train: Loss 0.7094 Acc 72.07% | Val: Loss 0.9868 Acc 61.61% | LR: 0.000500\n",
            "Epoch 50/100 | Train: Loss 0.7102 Acc 71.95% | Val: Loss 1.0437 Acc 59.72% | LR: 0.000500\n",
            "Epoch 51/100 | Train: Loss 0.6993 Acc 72.07% | Val: Loss 0.9521 Acc 64.62% | LR: 0.000500\n",
            "Epoch 52/100 | Train: Loss 0.6741 Acc 73.19% | Val: Loss 0.9145 Acc 63.00% | LR: 0.000500\n",
            "Epoch 53/100 | Train: Loss 0.6921 Acc 72.42% | Val: Loss 0.9499 Acc 63.70% | LR: 0.000250\n",
            "Epoch 54/100 | Train: Loss 0.6932 Acc 73.26% | Val: Loss 0.9211 Acc 64.66% | LR: 0.000250\n",
            "Epoch 55/100 | Train: Loss 0.6667 Acc 72.72% | Val: Loss 0.9164 Acc 64.20% | LR: 0.000250\n",
            "Epoch 56/100 | Train: Loss 0.6812 Acc 73.84% | Val: Loss 0.9075 Acc 65.39% | LR: 0.000250\n",
            "Epoch 57/100 | Train: Loss 0.6705 Acc 73.65% | Val: Loss 0.9109 Acc 65.28% | LR: 0.000250\n",
            "Epoch 58/100 | Train: Loss 0.6759 Acc 73.30% | Val: Loss 0.8867 Acc 65.01% | LR: 0.000250\n",
            "Epoch 59/100 | Train: Loss 0.6740 Acc 73.88% | Val: Loss 0.8978 Acc 65.97% | LR: 0.000250\n",
            "Epoch 60/100 | Train: Loss 0.6590 Acc 74.46% | Val: Loss 0.9236 Acc 65.93% | LR: 0.000250\n",
            "Epoch 61/100 | Train: Loss 0.6545 Acc 73.57% | Val: Loss 0.8823 Acc 65.70% | LR: 0.000250\n",
            "Epoch 62/100 | Train: Loss 0.6535 Acc 73.77% | Val: Loss 0.9162 Acc 65.78% | LR: 0.000250\n",
            "Epoch 63/100 | Train: Loss 0.6631 Acc 73.30% | Val: Loss 0.9043 Acc 65.28% | LR: 0.000250\n",
            "Epoch 64/100 | Train: Loss 0.6710 Acc 73.77% | Val: Loss 0.8907 Acc 65.93% | LR: 0.000250\n",
            "Epoch 65/100 | Train: Loss 0.6545 Acc 74.88% | Val: Loss 0.8751 Acc 65.93% | LR: 0.000125\n",
            "Epoch 66/100 | Train: Loss 0.6447 Acc 74.88% | Val: Loss 0.8761 Acc 66.28% | LR: 0.000125\n",
            "Epoch 67/100 | Train: Loss 0.6350 Acc 74.96% | Val: Loss 0.9025 Acc 66.05% | LR: 0.000125\n",
            "Epoch 68/100 | Train: Loss 0.6499 Acc 74.54% | Val: Loss 0.8978 Acc 65.90% | LR: 0.000125\n",
            "Epoch 69/100 | Train: Loss 0.6360 Acc 74.96% | Val: Loss 0.8968 Acc 65.93% | LR: 0.000125\n",
            "Epoch 70/100 | Train: Loss 0.6474 Acc 74.31% | Val: Loss 0.8914 Acc 65.74% | LR: 0.000125\n",
            "Epoch 71/100 | Train: Loss 0.6579 Acc 74.46% | Val: Loss 0.8941 Acc 65.55% | LR: 0.000125\n",
            "Epoch 72/100 | Train: Loss 0.6280 Acc 75.42% | Val: Loss 0.8838 Acc 65.78% | LR: 0.000063\n",
            "Epoch 73/100 | Train: Loss 0.6301 Acc 75.42% | Val: Loss 0.8840 Acc 65.82% | LR: 0.000063\n",
            "Epoch 74/100 | Train: Loss 0.6331 Acc 75.39% | Val: Loss 0.8944 Acc 65.82% | LR: 0.000063\n",
            "Epoch 75/100 | Train: Loss 0.6282 Acc 75.39% | Val: Loss 0.8914 Acc 65.78% | LR: 0.000063\n",
            "Epoch 76/100 | Train: Loss 0.6284 Acc 75.00% | Val: Loss 0.8912 Acc 65.55% | LR: 0.000063\n",
            "Epoch 77/100 | Train: Loss 0.6318 Acc 75.54% | Val: Loss 0.8859 Acc 66.24% | LR: 0.000063\n",
            "Epoch 78/100 | Train: Loss 0.6325 Acc 75.23% | Val: Loss 0.8926 Acc 66.36% | LR: 0.000063\n",
            "Epoch 79/100 | Train: Loss 0.6284 Acc 75.54% | Val: Loss 0.8835 Acc 66.67% | LR: 0.000063\n",
            "Epoch 80/100 | Train: Loss 0.6292 Acc 76.31% | Val: Loss 0.8901 Acc 66.24% | LR: 0.000063\n",
            "Epoch 81/100 | Train: Loss 0.6470 Acc 74.92% | Val: Loss 0.8888 Acc 66.28% | LR: 0.000063\n",
            "Epoch 82/100 | Train: Loss 0.6372 Acc 74.19% | Val: Loss 0.8740 Acc 66.09% | LR: 0.000063\n",
            "Epoch 83/100 | Train: Loss 0.6340 Acc 75.46% | Val: Loss 0.8754 Acc 66.09% | LR: 0.000063\n",
            "Epoch 84/100 | Train: Loss 0.6166 Acc 75.19% | Val: Loss 0.8787 Acc 66.13% | LR: 0.000063\n",
            "Epoch 85/100 | Train: Loss 0.6248 Acc 75.08% | Val: Loss 0.8814 Acc 66.24% | LR: 0.000031\n",
            "Epoch 86/100 | Train: Loss 0.6166 Acc 75.58% | Val: Loss 0.8896 Acc 66.32% | LR: 0.000031\n",
            "Epoch 87/100 | Train: Loss 0.6235 Acc 76.43% | Val: Loss 0.8998 Acc 65.90% | LR: 0.000031\n",
            "Epoch 88/100 | Train: Loss 0.6194 Acc 75.81% | Val: Loss 0.8874 Acc 66.32% | LR: 0.000031\n",
            "Epoch 89/100 | Train: Loss 0.6271 Acc 75.89% | Val: Loss 0.8988 Acc 66.05% | LR: 0.000031\n",
            "Epoch 90/100 | Train: Loss 0.6167 Acc 75.66% | Val: Loss 0.8943 Acc 66.13% | LR: 0.000031\n",
            "Epoch 91/100 | Train: Loss 0.6158 Acc 76.08% | Val: Loss 0.8982 Acc 65.93% | LR: 0.000016\n",
            "Epoch 92/100 | Train: Loss 0.6190 Acc 75.66% | Val: Loss 0.8949 Acc 66.09% | LR: 0.000016\n",
            "Epoch 93/100 | Train: Loss 0.6208 Acc 75.93% | Val: Loss 0.8953 Acc 65.86% | LR: 0.000016\n",
            "Epoch 94/100 | Train: Loss 0.6263 Acc 75.73% | Val: Loss 0.8919 Acc 66.05% | LR: 0.000016\n",
            "Epoch 95/100 | Train: Loss 0.6000 Acc 75.58% | Val: Loss 0.8899 Acc 65.97% | LR: 0.000016\n",
            "Epoch 96/100 | Train: Loss 0.6262 Acc 76.62% | Val: Loss 0.8862 Acc 65.97% | LR: 0.000016\n",
            "Epoch 97/100 | Train: Loss 0.6335 Acc 75.39% | Val: Loss 0.8968 Acc 65.90% | LR: 0.000008\n",
            "Epoch 98/100 | Train: Loss 0.6177 Acc 76.08% | Val: Loss 0.8900 Acc 66.20% | LR: 0.000008\n",
            "Epoch 99/100 | Train: Loss 0.6297 Acc 75.15% | Val: Loss 0.8845 Acc 66.36% | LR: 0.000008\n",
            "Epoch 100/100 | Train: Loss 0.6102 Acc 76.23% | Val: Loss 0.8945 Acc 65.93% | LR: 0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EnhancedEEGNetLSTM(nn.Module):\n",
        "    def __init__(self, n_classes=4, in_channels=26,\n",
        "                 F1=16, D=2, F2=32, kernel_length=64,\n",
        "                 dropout=0.3, lstm_units=128, bidirectional=True):\n",
        "        super(EnhancedEEGNetLSTM, self).__init__()\n",
        "\n",
        "        # Block 1\n",
        "        self.conv1 = nn.Conv2d(1, F1, (1, kernel_length),\n",
        "                               padding=(0, kernel_length//2),\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(F1)\n",
        "        self.depthwise = nn.Conv2d(F1, F1*D, (in_channels, 1),\n",
        "                                   groups=F1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(F1*D)\n",
        "        self.elu1 = nn.ELU()\n",
        "        self.pool1 = nn.AvgPool2d((1, 4))\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Block 2\n",
        "        self.sep_conv = nn.Conv2d(F1*D, F1*D, (1, 16),\n",
        "                                  padding=(0, 8),\n",
        "                                  groups=F1*D, bias=False)\n",
        "        self.pointwise = nn.Conv2d(F1*D, F2, (1, 1), bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(F2)\n",
        "        self.elu2 = nn.ELU()\n",
        "        self.pool2 = nn.AvgPool2d((1, 8))\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=F2,\n",
        "            hidden_size=lstm_units,\n",
        "            num_layers=2,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True,\n",
        "            dropout=0.2 if bidirectional else 0\n",
        "        )\n",
        "\n",
        "        # Dynamic classifier input features\n",
        "        lstm_output_size = lstm_units * 2 if bidirectional else lstm_units\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, lstm_output_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(lstm_output_size, 1, bias=False)\n",
        "        )\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(lstm_output_size, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.depthwise(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.elu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = self.sep_conv(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.elu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        # LSTM\n",
        "        x = x.squeeze(2)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # LSTM processing\n",
        "        x, _ = self.lstm(x)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attn_weights = torch.softmax(self.attention(x).squeeze(2), dim=1)\n",
        "        x = torch.sum(x * attn_weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        # Classification\n",
        "        x = self.drop3(x)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "TvjHZxfDVFlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EnhancedEEGNetLSTM().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                             lr=0.001,\n",
        "                             weight_decay=0.01)\n",
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=8,  # Increased patience\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-34ObldVOA0",
        "outputId": "e2f83ad3-c588-4173-f8c9-4217e403403d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, test_loader, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUlnYer_YCRq",
        "outputId": "4445ea37-872b-4dc7-9b1b-3789cb26a45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Train: Loss 1.3867 Acc 25.58% | Val: Loss 1.3864 Acc 25.00% | LR: 0.001000\n",
            "Epoch 2/100 | Train: Loss 1.3361 Acc 35.07% | Val: Loss 1.3998 Acc 25.00% | LR: 0.001000\n",
            "Epoch 3/100 | Train: Loss 1.2771 Acc 41.59% | Val: Loss 1.3945 Acc 25.00% | LR: 0.001000\n",
            "Epoch 4/100 | Train: Loss 1.1870 Acc 49.27% | Val: Loss 1.5217 Acc 26.27% | LR: 0.001000\n",
            "Epoch 5/100 | Train: Loss 1.0589 Acc 55.48% | Val: Loss 1.3208 Acc 32.21% | LR: 0.001000\n",
            "Epoch 6/100 | Train: Loss 1.0291 Acc 57.75% | Val: Loss 1.2232 Acc 44.71% | LR: 0.001000\n",
            "Epoch 7/100 | Train: Loss 0.9571 Acc 61.07% | Val: Loss 1.5830 Acc 26.77% | LR: 0.001000\n",
            "Epoch 8/100 | Train: Loss 0.8973 Acc 63.89% | Val: Loss 1.6493 Acc 29.13% | LR: 0.001000\n",
            "Epoch 9/100 | Train: Loss 0.8613 Acc 65.51% | Val: Loss 1.3175 Acc 51.16% | LR: 0.001000\n",
            "Epoch 10/100 | Train: Loss 0.8255 Acc 66.51% | Val: Loss 1.2545 Acc 49.15% | LR: 0.001000\n",
            "Epoch 11/100 | Train: Loss 0.8093 Acc 67.13% | Val: Loss 2.4356 Acc 31.98% | LR: 0.001000\n",
            "Epoch 12/100 | Train: Loss 0.7663 Acc 69.14% | Val: Loss 2.1575 Acc 27.93% | LR: 0.001000\n",
            "Epoch 13/100 | Train: Loss 0.7175 Acc 70.72% | Val: Loss 1.6650 Acc 42.13% | LR: 0.001000\n",
            "Epoch 14/100 | Train: Loss 0.7060 Acc 72.07% | Val: Loss 1.2610 Acc 55.98% | LR: 0.001000\n",
            "Epoch 15/100 | Train: Loss 0.6846 Acc 72.99% | Val: Loss 1.2633 Acc 50.46% | LR: 0.001000\n",
            "Epoch 16/100 | Train: Loss 0.6508 Acc 76.12% | Val: Loss 1.2289 Acc 55.75% | LR: 0.001000\n",
            "Epoch 17/100 | Train: Loss 0.6314 Acc 74.61% | Val: Loss 2.6380 Acc 27.82% | LR: 0.001000\n",
            "Epoch 18/100 | Train: Loss 0.5948 Acc 77.39% | Val: Loss 1.4474 Acc 52.16% | LR: 0.001000\n",
            "Epoch 19/100 | Train: Loss 0.5682 Acc 78.94% | Val: Loss 1.1593 Acc 57.06% | LR: 0.001000\n",
            "Epoch 20/100 | Train: Loss 0.5644 Acc 77.74% | Val: Loss 1.3779 Acc 52.97% | LR: 0.001000\n",
            "Epoch 21/100 | Train: Loss 0.5450 Acc 78.51% | Val: Loss 1.6262 Acc 47.45% | LR: 0.001000\n",
            "Epoch 22/100 | Train: Loss 0.5324 Acc 79.90% | Val: Loss 1.0173 Acc 63.62% | LR: 0.001000\n",
            "Epoch 23/100 | Train: Loss 0.4924 Acc 81.87% | Val: Loss 1.7393 Acc 47.42% | LR: 0.001000\n",
            "Epoch 24/100 | Train: Loss 0.5033 Acc 80.63% | Val: Loss 0.9702 Acc 65.05% | LR: 0.001000\n",
            "Epoch 25/100 | Train: Loss 0.4770 Acc 82.21% | Val: Loss 1.4152 Acc 56.44% | LR: 0.001000\n",
            "Epoch 26/100 | Train: Loss 0.4930 Acc 81.83% | Val: Loss 1.2893 Acc 50.39% | LR: 0.001000\n",
            "Epoch 27/100 | Train: Loss 0.4288 Acc 83.99% | Val: Loss 1.0055 Acc 62.27% | LR: 0.001000\n",
            "Epoch 28/100 | Train: Loss 0.3869 Acc 86.03% | Val: Loss 1.2717 Acc 60.61% | LR: 0.001000\n",
            "Epoch 29/100 | Train: Loss 0.4071 Acc 85.65% | Val: Loss 2.4029 Acc 43.56% | LR: 0.001000\n",
            "Epoch 30/100 | Train: Loss 0.3704 Acc 87.00% | Val: Loss 1.2078 Acc 59.84% | LR: 0.001000\n",
            "Epoch 31/100 | Train: Loss 0.4003 Acc 84.68% | Val: Loss 1.2314 Acc 62.77% | LR: 0.001000\n",
            "Epoch 32/100 | Train: Loss 0.3566 Acc 87.19% | Val: Loss 1.0939 Acc 65.55% | LR: 0.001000\n",
            "Epoch 33/100 | Train: Loss 0.3315 Acc 88.08% | Val: Loss 1.2503 Acc 60.53% | LR: 0.001000\n",
            "Epoch 34/100 | Train: Loss 0.2972 Acc 88.89% | Val: Loss 1.0678 Acc 67.21% | LR: 0.001000\n",
            "Epoch 35/100 | Train: Loss 0.2792 Acc 90.24% | Val: Loss 1.5358 Acc 59.22% | LR: 0.001000\n",
            "Epoch 36/100 | Train: Loss 0.2723 Acc 90.12% | Val: Loss 1.2961 Acc 49.73% | LR: 0.001000\n",
            "Epoch 37/100 | Train: Loss 0.2497 Acc 91.55% | Val: Loss 1.4568 Acc 54.01% | LR: 0.001000\n",
            "Epoch 38/100 | Train: Loss 0.2480 Acc 91.71% | Val: Loss 1.7131 Acc 51.97% | LR: 0.001000\n",
            "Epoch 39/100 | Train: Loss 0.2354 Acc 92.13% | Val: Loss 2.5766 Acc 40.16% | LR: 0.001000\n",
            "Epoch 40/100 | Train: Loss 0.2631 Acc 90.55% | Val: Loss 2.4607 Acc 45.99% | LR: 0.001000\n",
            "Epoch 41/100 | Train: Loss 0.2182 Acc 92.48% | Val: Loss 1.2449 Acc 66.67% | LR: 0.001000\n",
            "Epoch 42/100 | Train: Loss 0.1812 Acc 94.33% | Val: Loss 1.3993 Acc 61.61% | LR: 0.001000\n",
            "Epoch 43/100 | Train: Loss 0.2118 Acc 92.21% | Val: Loss 2.2840 Acc 46.10% | LR: 0.000500\n",
            "Epoch 44/100 | Train: Loss 0.1604 Acc 94.87% | Val: Loss 1.1988 Acc 67.01% | LR: 0.000500\n",
            "Epoch 45/100 | Train: Loss 0.1317 Acc 95.91% | Val: Loss 1.6386 Acc 59.22% | LR: 0.000500\n",
            "Epoch 46/100 | Train: Loss 0.1128 Acc 96.10% | Val: Loss 1.2067 Acc 68.94% | LR: 0.000500\n",
            "Epoch 47/100 | Train: Loss 0.0918 Acc 97.15% | Val: Loss 1.1835 Acc 67.90% | LR: 0.000500\n",
            "Epoch 48/100 | Train: Loss 0.1008 Acc 96.95% | Val: Loss 1.4045 Acc 67.98% | LR: 0.000500\n",
            "Epoch 49/100 | Train: Loss 0.0939 Acc 96.91% | Val: Loss 1.3218 Acc 66.74% | LR: 0.000500\n",
            "Epoch 50/100 | Train: Loss 0.0947 Acc 97.11% | Val: Loss 1.6147 Acc 61.81% | LR: 0.000500\n",
            "Epoch 51/100 | Train: Loss 0.0929 Acc 96.91% | Val: Loss 1.3340 Acc 66.98% | LR: 0.000500\n",
            "Epoch 52/100 | Train: Loss 0.0767 Acc 97.53% | Val: Loss 1.7190 Acc 60.80% | LR: 0.000500\n",
            "Epoch 53/100 | Train: Loss 0.0921 Acc 96.95% | Val: Loss 1.3037 Acc 68.60% | LR: 0.000500\n",
            "Epoch 54/100 | Train: Loss 0.0887 Acc 97.53% | Val: Loss 1.6614 Acc 62.00% | LR: 0.000500\n",
            "Epoch 55/100 | Train: Loss 0.0824 Acc 96.99% | Val: Loss 1.3198 Acc 64.35% | LR: 0.000250\n",
            "Epoch 56/100 | Train: Loss 0.0691 Acc 97.92% | Val: Loss 1.3518 Acc 68.13% | LR: 0.000250\n",
            "Epoch 57/100 | Train: Loss 0.0606 Acc 98.26% | Val: Loss 1.3239 Acc 69.29% | LR: 0.000250\n",
            "Epoch 58/100 | Train: Loss 0.0553 Acc 98.42% | Val: Loss 1.4124 Acc 68.87% | LR: 0.000250\n",
            "Epoch 59/100 | Train: Loss 0.0436 Acc 98.53% | Val: Loss 1.3065 Acc 68.83% | LR: 0.000250\n",
            "Epoch 60/100 | Train: Loss 0.0421 Acc 98.88% | Val: Loss 1.4027 Acc 67.82% | LR: 0.000250\n",
            "Epoch 61/100 | Train: Loss 0.0387 Acc 99.04% | Val: Loss 1.3232 Acc 69.91% | LR: 0.000250\n",
            "Epoch 62/100 | Train: Loss 0.0363 Acc 99.07% | Val: Loss 1.3816 Acc 69.79% | LR: 0.000250\n",
            "Epoch 63/100 | Train: Loss 0.0352 Acc 98.96% | Val: Loss 1.4173 Acc 69.14% | LR: 0.000250\n",
            "Epoch 64/100 | Train: Loss 0.0437 Acc 98.77% | Val: Loss 1.4029 Acc 69.64% | LR: 0.000250\n",
            "Epoch 65/100 | Train: Loss 0.0327 Acc 99.11% | Val: Loss 1.4190 Acc 69.95% | LR: 0.000250\n",
            "Epoch 66/100 | Train: Loss 0.0315 Acc 99.34% | Val: Loss 1.4411 Acc 69.91% | LR: 0.000250\n",
            "Epoch 67/100 | Train: Loss 0.0371 Acc 98.88% | Val: Loss 1.4553 Acc 68.71% | LR: 0.000250\n",
            "Epoch 68/100 | Train: Loss 0.0337 Acc 99.11% | Val: Loss 1.4563 Acc 68.63% | LR: 0.000250\n",
            "Epoch 69/100 | Train: Loss 0.0342 Acc 99.04% | Val: Loss 1.4119 Acc 69.25% | LR: 0.000250\n",
            "Epoch 70/100 | Train: Loss 0.0327 Acc 99.07% | Val: Loss 1.4664 Acc 68.83% | LR: 0.000250\n",
            "Epoch 71/100 | Train: Loss 0.0347 Acc 99.23% | Val: Loss 1.4866 Acc 69.75% | LR: 0.000250\n",
            "Epoch 72/100 | Train: Loss 0.0355 Acc 99.04% | Val: Loss 1.4060 Acc 68.83% | LR: 0.000250\n",
            "Epoch 73/100 | Train: Loss 0.0384 Acc 98.84% | Val: Loss 1.5805 Acc 67.90% | LR: 0.000250\n",
            "Epoch 74/100 | Train: Loss 0.0340 Acc 99.00% | Val: Loss 1.6085 Acc 67.52% | LR: 0.000125\n",
            "Epoch 75/100 | Train: Loss 0.0302 Acc 99.15% | Val: Loss 1.4548 Acc 70.14% | LR: 0.000125\n",
            "Epoch 76/100 | Train: Loss 0.0345 Acc 99.00% | Val: Loss 1.4324 Acc 69.64% | LR: 0.000125\n",
            "Epoch 77/100 | Train: Loss 0.0290 Acc 99.15% | Val: Loss 1.4517 Acc 69.60% | LR: 0.000125\n",
            "Epoch 78/100 | Train: Loss 0.0272 Acc 99.23% | Val: Loss 1.4519 Acc 69.79% | LR: 0.000125\n",
            "Epoch 79/100 | Train: Loss 0.0260 Acc 99.27% | Val: Loss 1.4492 Acc 69.98% | LR: 0.000125\n",
            "Epoch 80/100 | Train: Loss 0.0305 Acc 99.27% | Val: Loss 1.4725 Acc 69.14% | LR: 0.000125\n",
            "Epoch 81/100 | Train: Loss 0.0244 Acc 99.23% | Val: Loss 1.5438 Acc 69.41% | LR: 0.000125\n",
            "Epoch 82/100 | Train: Loss 0.0321 Acc 99.00% | Val: Loss 1.5311 Acc 69.68% | LR: 0.000125\n",
            "Epoch 83/100 | Train: Loss 0.0256 Acc 99.46% | Val: Loss 1.5040 Acc 69.41% | LR: 0.000125\n",
            "Epoch 84/100 | Train: Loss 0.0281 Acc 99.23% | Val: Loss 1.5317 Acc 69.41% | LR: 0.000063\n",
            "Epoch 85/100 | Train: Loss 0.0232 Acc 99.23% | Val: Loss 1.5073 Acc 69.52% | LR: 0.000063\n",
            "Epoch 86/100 | Train: Loss 0.0246 Acc 99.23% | Val: Loss 1.5112 Acc 69.25% | LR: 0.000063\n",
            "Epoch 87/100 | Train: Loss 0.0216 Acc 99.38% | Val: Loss 1.4999 Acc 69.29% | LR: 0.000063\n",
            "Epoch 88/100 | Train: Loss 0.0195 Acc 99.46% | Val: Loss 1.4942 Acc 69.64% | LR: 0.000063\n",
            "Epoch 89/100 | Train: Loss 0.0167 Acc 99.69% | Val: Loss 1.4793 Acc 69.64% | LR: 0.000063\n",
            "Epoch 90/100 | Train: Loss 0.0187 Acc 99.38% | Val: Loss 1.4720 Acc 69.64% | LR: 0.000063\n",
            "Epoch 91/100 | Train: Loss 0.0148 Acc 99.73% | Val: Loss 1.4890 Acc 69.41% | LR: 0.000063\n",
            "Epoch 92/100 | Train: Loss 0.0223 Acc 99.54% | Val: Loss 1.5399 Acc 69.48% | LR: 0.000063\n",
            "Epoch 93/100 | Train: Loss 0.0223 Acc 99.42% | Val: Loss 1.5128 Acc 69.17% | LR: 0.000031\n",
            "Epoch 94/100 | Train: Loss 0.0233 Acc 99.27% | Val: Loss 1.5154 Acc 69.60% | LR: 0.000031\n",
            "Epoch 95/100 | Train: Loss 0.0214 Acc 99.46% | Val: Loss 1.5170 Acc 69.52% | LR: 0.000031\n",
            "Epoch 96/100 | Train: Loss 0.0215 Acc 99.38% | Val: Loss 1.5107 Acc 69.52% | LR: 0.000031\n",
            "Epoch 97/100 | Train: Loss 0.0183 Acc 99.42% | Val: Loss 1.5048 Acc 69.60% | LR: 0.000031\n",
            "Epoch 98/100 | Train: Loss 0.0188 Acc 99.54% | Val: Loss 1.5223 Acc 69.68% | LR: 0.000031\n",
            "Epoch 99/100 | Train: Loss 0.0177 Acc 99.58% | Val: Loss 1.5264 Acc 69.75% | LR: 0.000031\n",
            "Epoch 100/100 | Train: Loss 0.0218 Acc 99.46% | Val: Loss 1.5087 Acc 69.56% | LR: 0.000031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results:\n",
        "max accuracy on validation set is 70.14% and it was achived by EnhancedEEGNetLSTM on Epoch 75"
      ],
      "metadata": {
        "id": "xChysbOepJ6M"
      }
    }
  ]
}