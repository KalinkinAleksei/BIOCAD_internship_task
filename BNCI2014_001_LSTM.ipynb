{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fUZj-JZ6SDT",
    "outputId": "16a2b47b-4965-4a1d-f2ef-515122b81aad"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from scipy.signal import firwin, freqz, lfilter, welch\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "!pip install mne\n",
    "!pip install moabb\n",
    "!pip install braindecode\n",
    "\n",
    "import mne\n",
    "import moabb\n",
    "from mne.decoding import CSP\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyBU01jF_2Kq"
   },
   "outputs": [],
   "source": [
    "from braindecode.datasets import MOABBDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WY6p-BwN-9xo"
   },
   "outputs": [],
   "source": [
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids = [i for i in range(1, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CFjOQGxCt6S",
    "outputId": "cae2a595-0359-45c9-e91d-dfb4ae67e022"
   },
   "outputs": [],
   "source": [
    "from braindecode.preprocessing import create_windows_from_events\n",
    "\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info[\"sfreq\"]\n",
    "assert all([ds.raw.info[\"sfreq\"] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the trial start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to define how\n",
    "# trials should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHSeDffDBWqw"
   },
   "outputs": [],
   "source": [
    "splitted = windows_dataset.split(\"session\")\n",
    "train_set = splitted['0train']  # Session train\n",
    "test_set = splitted['1test']  # Session evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVCnZ24dJew6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHozUgyDBlxK"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "fe930e70550a40fa8e8a055a8bcb1859",
      "c750a835127243a5b15f1b798fb082b7",
      "d2dfa28ce8994379b976410df53cd28d",
      "fcf34890e24f42af8835215058fbbbe0",
      "285ff74a2d69467bb3f8b549f31c122e",
      "e9e7a7bc82b743c9a33310acad5b0d83",
      "b6be201049df450bbcca7926198e74bc",
      "69d9c9d345f04831af50367ec90757a9",
      "a63e5553af774f6ab2f3a5509f5979b9",
      "e9af8d683a024bfabf5ad20f83bb1dba",
      "aed5aa0d862c446e9ce7ed41a4b26803"
     ]
    },
    "id": "wsxo23s5B42k",
    "outputId": "5a565232-2ab4-4996-d843-8df8a7295a4d"
   },
   "outputs": [],
   "source": [
    "progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "for batch_idx, (X, y, _) in progress_bar:\n",
    "  print(X.shape, y.shape)\n",
    "  print(y)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs3C8cJ8OWe5"
   },
   "outputs": [],
   "source": [
    "class EEGNetLSTM(nn.Module):\n",
    "    def __init__(self, n_classes=4, in_channels=26,\n",
    "                 F1=8, D=2, F2=16, kernel_length=64,\n",
    "                 dropout=0.25, lstm_units=64):\n",
    "        super(EEGNetLSTM, self).__init__()\n",
    "\n",
    "        # Block 1: Spatial-temporal features\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, kernel_length),\n",
    "                              padding=(0, kernel_length//2),\n",
    "                              bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.depthwise = nn.Conv2d(F1, F1*D, (in_channels, 1),\n",
    "                                  groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1*D)\n",
    "        self.elu1 = nn.ELU()\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        # Block 2: Temporal compression\n",
    "        self.sep_conv = nn.Conv2d(F1*D, F1*D, (1, 16),\n",
    "                                 padding=(0, 8),\n",
    "                                 groups=F1*D, bias=False)\n",
    "        self.pointwise = nn.Conv2d(F1*D, F2, (1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.elu2 = nn.ELU()\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=F2,\n",
    "            hidden_size=lstm_units,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.classifier = nn.Linear(lstm_units, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.elu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.sep_conv(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.elu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = x.squeeze(2)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZJc1yuwPiEa",
    "outputId": "fa3a9ef4-3901-47cc-ad5a-e1a52419fedc"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EEGNetLSTM().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "def train(model, train_loader, test_loader, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y, _ in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += y.size(0)\n",
    "                val_correct += predicted.eq(y).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train: Loss {avg_train_loss:.4f} Acc {train_acc:.2f}% | \"\n",
    "              f\"Val: Loss {avg_val_loss:.4f} Acc {val_acc:.2f}% | \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "train(model, train_loader, test_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvjHZxfDVFlT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EnhancedEEGNetLSTM(nn.Module):\n",
    "    def __init__(self, n_classes=4, in_channels=26,\n",
    "                 F1=16, D=2, F2=32, kernel_length=64,\n",
    "                 dropout=0.3, lstm_units=128, bidirectional=True):\n",
    "        super(EnhancedEEGNetLSTM, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, kernel_length),\n",
    "                               padding=(0, kernel_length//2),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.depthwise = nn.Conv2d(F1, F1*D, (in_channels, 1),\n",
    "                                   groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1*D)\n",
    "        self.elu1 = nn.ELU()\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        # Block 2\n",
    "        self.sep_conv = nn.Conv2d(F1*D, F1*D, (1, 16),\n",
    "                                  padding=(0, 8),\n",
    "                                  groups=F1*D, bias=False)\n",
    "        self.pointwise = nn.Conv2d(F1*D, F2, (1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.elu2 = nn.ELU()\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=F2,\n",
    "            hidden_size=lstm_units,\n",
    "            num_layers=2,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=0.2 if bidirectional else 0\n",
    "        )\n",
    "\n",
    "        # Dynamic classifier input features\n",
    "        lstm_output_size = lstm_units * 2 if bidirectional else lstm_units\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(lstm_output_size, lstm_output_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(lstm_output_size, 1, bias=False)\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(lstm_output_size, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.elu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.sep_conv(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.elu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        # LSTM\n",
    "        x = x.squeeze(2)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # LSTM processing\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = torch.softmax(self.attention(x).squeeze(2), dim=1)\n",
    "        x = torch.sum(x * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "        # Classification\n",
    "        x = self.drop3(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-34ObldVOA0",
    "outputId": "e2f83ad3-c588-4173-f8c9-4217e403403d"
   },
   "outputs": [],
   "source": [
    "model = EnhancedEEGNetLSTM().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                             lr=0.001,\n",
    "                             weight_decay=0.01)\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=8,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUlnYer_YCRq",
    "outputId": "4445ea37-872b-4dc7-9b1b-3789cb26a45b"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, test_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xChysbOepJ6M"
   },
   "source": [
    "# Results:\n",
    "max accuracy on validation set is 70.14% and it was achived by EnhancedEEGNetLSTM on Epoch 75"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "285ff74a2d69467bb3f8b549f31c122e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69d9c9d345f04831af50367ec90757a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a63e5553af774f6ab2f3a5509f5979b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aed5aa0d862c446e9ce7ed41a4b26803": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6be201049df450bbcca7926198e74bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c750a835127243a5b15f1b798fb082b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9e7a7bc82b743c9a33310acad5b0d83",
      "placeholder": "​",
      "style": "IPY_MODEL_b6be201049df450bbcca7926198e74bc",
      "value": "  0%"
     }
    },
    "d2dfa28ce8994379b976410df53cd28d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d9c9d345f04831af50367ec90757a9",
      "max": 162,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a63e5553af774f6ab2f3a5509f5979b9",
      "value": 0
     }
    },
    "e9af8d683a024bfabf5ad20f83bb1dba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9e7a7bc82b743c9a33310acad5b0d83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcf34890e24f42af8835215058fbbbe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9af8d683a024bfabf5ad20f83bb1dba",
      "placeholder": "​",
      "style": "IPY_MODEL_aed5aa0d862c446e9ce7ed41a4b26803",
      "value": " 0/162 [00:00&lt;?, ?it/s]"
     }
    },
    "fe930e70550a40fa8e8a055a8bcb1859": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c750a835127243a5b15f1b798fb082b7",
       "IPY_MODEL_d2dfa28ce8994379b976410df53cd28d",
       "IPY_MODEL_fcf34890e24f42af8835215058fbbbe0"
      ],
      "layout": "IPY_MODEL_285ff74a2d69467bb3f8b549f31c122e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
